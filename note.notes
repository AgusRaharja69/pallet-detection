TASK THESIS:
1.  Method 1, Record data
2.  Method 2, Record data
3.  Method 3, Edit Code, Record Data

Command training model :
py train.py --img 320 --batch 8 --epochs 50 --data data.yaml --device 0 --weights yolov5n.pt
py train.py --img 320 --batch 8 --epochs 10 --data data.yaml --device 0 --weights yolov5n.pt

Command detection:
py detectPallet.py --source 1 --device 0 --weights runs/train/exp21/weights/best.pt --weights-name yolov5n-100 --img 320
py yoloDetection.py --weights runs/train/exp16/weights/best.pt --weights-name yolov5s-100 --img 320

Weights name:
- yolov5m-10 : exp11
- yolov5m-25 : exp12
- yolov5m-50 : exp13
- yolov5m-75 : exp14
- yolov5m-100 : exp15
//
- yolov5s-100 : exp16
- yolov5s-75 : exp17
- yolov5s-50 : exp18
- yolov5s-25 : exp19
- yolov5s-10 : exp20
//
- yolov5n-100 : exp21
- yolov5n-75 : exp22
- yolov5n-50 : exp23
- yolov5n-25 : exp27
- yolov5n-10 : exp28

################## RUN DATA ##################
Focal length camera:
yolov5m [952.0,954.0,954.0,952.0,954.0,952.0,952.0,952.0,952.0,954.0,952.0,952.0,954.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0,954.0,952.0,952.0,954.0,954.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0,954.0,952.0,952.0,954.0,952.0,952.0,952.0,954.0,952.0,952.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0]
yolov5s [992.0,988.0,988.0,980.0,988.0,996.0,986.0,986.0,992.0,984.0,984.0,990.0,996.0,994.0,996.0,986.0,990.0,994.0,988.0,996.0,982.0,994.0,980.0,980.0,992.0,988.0,990.0,990.0,990.0,990.0,996.0,996.0,992.0,998.0,998.0,992.0,990.0,986.0,982.0,994.0,984.0,994.0,990.0,982.0,988.0,988.0,984.0,996.0,980.0,994.0,988.0,990.0,984.0,990.0,992.0,986.0,996.0,996.0,974.0,988.0,988.0,978.0,988.0,990.0,990.0,990.0,976.0,978.0,988.0,986.0,990.0,990.0,998.0,992.0,982.0,992.0,992.0,988.0,990.0,990.0,986.0,990.0,986.0,992.0,990.0,992.0,994.0,994.0,994.0,994.0,990.0,990.0,992.0,986.0,992.0,994.0,994.0,986.0,992.0,994.0,984.0,990.0,998.0,992.0,988.0,994.0,984.0,980.0,982.0,994.0,994.0,982.0,994.0,982.0,982.0,992.0,992.0,994.0,994.0,992.0,992.0,990.0,994.0,982.0,994.0,984.0,984.0,992.0,994.0,996.0,992.0,992.0,986.0,994.0,990.0,980.0,988.0,988.0,970.0,988.0,988.0,982.0,982.0,990.0,990.0,986.0,990.0,990.0,988.0,992.0,994.0,980.0,994.0,988.0,990.0,986.0,982.0]
yolov5n [980.0,982.0,970.0,982.0,966.0,966.0,976.0,980.0,986.0,982.0,962.0,980.0,968.0,976.0,962.0,968.0,968.0,984.0,980.0,984.0,982.0,976.0,978.0,972.0,974.0,984.0,988.0,976.0,954.0,974.0,974.0,976.0,976.0,974.0,974.0,980.0,974.0,968.0,968.0,982.0,972.0,978.0,978.0,976.0,980.0,956.0,972.0,980.0,954.0,976.0,980.0,978.0,988.0,980.0,978.0,978.0,978.0,976.0,976.0,984.0,964.0,964.0,982.0,978.0,984.0,964.0,988.0,988.0,980.0,992.0]

Distance using method 1:
[1] 100
m1 (99.797) = [99.655,99.864,99.864,99.864,99.655,99.865,99.655,99.864,99.655,99.655,99.865,99.655,99.655,100.074,99.864,100.074,99.865,99.655,99.655,99.864,99.655,99.864,99.864,99.864,99.864,99.655,99.655,99.655,99.864,99.864,100.074]
s1 (101.208) = [101.34,101.34,101.132,101.132,100.927,101.132,100.721,101.133,103.039,101.132,101.34,101.133,101.133,101.133,100.927,101.134,101.34,101.133,101.34,101.133,101.133,101.133,101.34,101.133,100.927,100.927,101.132,100.927,101.133,101.34,101.548]
n1 (102.874) = [103.387,103.169,105.863,102.515,102.515,103.609,102.517,102.302,101.661,102.302,102.302,104.051,102.517,102.517,102.517,100.818,102.302,102.951,102.951,103.609,102.517,102.517,102.517,101.875,102.951,103.829,103.829,102.951,102.086,104.053,103.609]
[2] 150
[3] 200
[4] 250
[5] 300
[6] 350

LiDAR real world potition:
h_LiDAR = 10.5 cm
h_camera = 14.5 cm

#########################################################################
D:\TESIS\THESIS_3\program\pallet-detection\data-collection\camera-callibration>py test_fusion.py
camera_matrix:  [[1.57034678e+03 0.00000000e+00 3.75793671e+02]
 [0.00000000e+00 1.49880818e+03 3.65519559e+02]
 [0.00000000e+00 0.00000000e+00 1.00000000e+00]]
rvecs:  [array([[ 0.08995302],
       [-0.36658966],
       [-0.00513899]])]
tvecs:  [array([[-4.71874415],
       [-6.94724055],
       [35.31130224]])]

rotation_matrix:  [[ 0.93358714 -0.01127525 -0.35817302]
 [-0.02131085  0.995989   -0.0869009 ]
 [ 0.35771622  0.08876254  0.92960224]]

translation_vector:  [-0.47187442  3.52812558 -0.47187442]

extrinsic_matrix:  [[ 0.93358714 -0.01127525 -0.35817302 -0.47187442]
 [-0.02131085  0.995989   -0.0869009   3.52812558]
 [ 0.35771622  0.08876254  0.92960224 -0.47187442]
 [ 0.          0.          0.          1.        ]]
camera_to_lidar:  [[ 0.93358714 -0.02131085  0.35771622  0.68452038]
 [-0.01127525  0.995989    0.08876254 -3.47740999]
 [-0.35817302 -0.0869009   0.92960224  0.57624013]
 [ 0.          0.          0.          1.        ]]

 #########################################################################
D:\TESIS\THESIS_3\program\pallet-detection\data-collection>py callibration-camera.py
camera_matrix:  [[502.56912538   0.         371.18295742]
 [  0.         518.77865677 123.60822693]
 [  0.           0.           1.        ]]
rotation_matrix:  [[ 0.98450658 -0.03044044 -0.17268519]
 [ 0.02700893  0.99938894 -0.022187  ]
 [ 0.17325505  0.0171792   0.98472715]]
translation_vector:  [-0.47797807  3.52202193 -0.47797807]
extrinsic_matrix:  [[ 0.98450658 -0.03044044 -0.17268519 -0.47797807]
 [ 0.02700893  0.99938894 -0.022187    3.52202193]
 [ 0.17325505  0.0171792   0.98472715 -0.47797807]
 [ 0.          0.          0.          1.        ]]
camera_to_lidar:  [[ 0.98450658  0.02700893  0.17325505  0.45825861]
 [-0.03044044  0.99938894  0.0171792  -3.52620835]
 [-0.17268519 -0.022187    0.98472715  0.46628134]
 [ 0.          0.          0.          1.        ]]

 - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!:
 D:\TESIS\THESIS_3\program\pallet-detection\data-collection>py callibration-camera.py
camera_matrix:  [[437.81464946   0.         250.51843603]
 [  0.         421.31344926 242.87899323]
 [  0.           0.           1.        ]]

dist:  [[-0.39328142  1.14971779 -0.05502625  0.01450477 -1.59749278]]

rotation_matrix:  [[ 0.99216097 -0.00893324 -0.1246467 ]
 [ 0.00491244  0.99945876 -0.03252774]
 [ 0.12486981  0.03166044  0.99166786]]

translation_vector:  [-0.18843171  3.81156829 -0.18843171]

extrinsic_matrix:  [[ 0.99216097 -0.00893324 -0.1246467  -0.18843171]
 [ 0.00491244  0.99945876 -0.03252774  3.81156829]
 [ 0.12486981  0.03166044  0.99166786 -0.18843171]
 [ 0.          0.          0.          1.        ]]

camera_to_lidar:  [[ 0.99216097  0.00491244  0.12486981  0.19175992]
 [-0.00893324  0.99945876  0.03166044 -3.8052228 ]
 [-0.1246467  -0.03252774  0.99166786  0.28735599]
 [ 0.          0.          0.          1.        ]]

 - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!:
D:\TESIS\THESIS_3\program\pallet-detection\data-collection>py calibration-camera.py
camera_matrix:  [[1.86091182e+03 0.00000000e+00 3.93702380e+02]
 [0.00000000e+00 1.84606954e+03 4.09530228e+02]
 [0.00000000e+00 0.00000000e+00 1.00000000e+00]]

dist:  [[-3.12480991e+00  1.20483327e+02  7.63097732e-03 -5.64181108e-03
  -1.42623193e+03]]

rotation_matrix:  [[ 0.9971224  -0.02865836 -0.07018272]
 [ 0.01826659  0.98934144 -0.14446401]
 [ 0.07357478  0.1427663   0.987018  ]]

translation_vector:  [-0.48266557  3.51733443 -0.48266557]

extrinsic_matrix:  [[ 0.9971224  -0.02865836 -0.07018272 -0.48266557]
 [ 0.01826659  0.98934144 -0.14446401  3.51733443]
 [ 0.07357478  0.1427663   0.987018   -0.48266557]
 [ 0.          0.          0.          1.        ]]

camera_to_lidar:  [[ 0.9971224   0.01826659  0.07357478  0.45253898]
 [-0.02865836  0.98934144  0.1427663  -3.42476872]
 [-0.07018272 -0.14446401  0.987018    0.95065307]
 [ 0.          0.          0.          1.        ]]

 - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!:
D:\TESIS\THESIS_3\program\pallet-detection\data-collection>py calibration-camera.py
Camera parameters
Lens = pinhole
K =
[[1.86091182e+03 0.00000000e+00 3.93702380e+02]
 [0.00000000e+00 1.84606954e+03 4.09530228e+02]
 [0.00000000e+00 0.00000000e+00 1.00000000e+00]]
D =
[-3.12480991e+00  1.20483327e+02  7.63097732e-03 -5.64181108e-03]
Transform from camera to laser
T =
[[-4.86069745]
 [-7.98533984]
 [43.65714024]]
R =
[[ 0.99970798 -0.02403403 -0.0025132 ]
 [ 0.02402181  0.99969998 -0.00478546]
 [ 0.00262746  0.00472369  0.99998539]]
RMSE in pixel = 10.89423783140845
Result output format: qx qy qz qw tx ty tz


###################### error #########################
###################### error #########################
import cv2
import numpy as np
import json

jsonLidarPath = '../lidarJson.json'

# Calibration parameters - adjust according to your setup
lidar_height = 10.5  # cm
camera_height = 14.5  # cm
image_width = 640
image_height = 480

fx = float(1570.34678)
fy = float(1498.80818)
cx = float(375.793671)
cy = float(365.519559)

camera_matrix = np.matrix(
                [[fx, 0.0, cx],
                [0.0, fy, cy],
                [0.0, 0.0, 1.0]])

camera_to_lidar = np.matrix(
            [[ 0.93358714, -0.02131085, 0.35771622, 0.68452038],
            [-0.01127525, 0.995989, 0.08876254, -3.47740999],
            [-0.35817302, -0.0869009, 0.92960224, 0.57624013],
            [ 0.0, 0.0, 0.0, 1.0]])

# Capture and calibrate the camera
cap = cv2.VideoCapture(1)

while True:
    # Capture frame from webcam
    ret, frame = cap.read()

    # Lidar points in polar coordinates
    with open(jsonLidarPath) as f:
        try :
            lidar_data = json.load(f)
        except:
            lidar_data = {"data": [[0,0,0]]}

    # LiDAR data
    dataLidar = np.array(lidar_data['data'])
    angleRawLidar = np.radians(dataLidar[:, 1]) # Convert angle to radians
    distance = dataLidar[:, 2] #lidar distance
    angle = np.pi - angleRawLidar #lidar angle

    # Convert polar coordinates to 3D cartesian coordinates in lidar frame
    x = distance * np.sin(angle)
    y = -distance * np.cos(angle)
    z = np.zeros_like(x)
    lidar_pos = np.column_stack([x, y, z, np.ones_like(distance)])

    # Transform lidar points to camera frame
    camera_pos = np.dot(camera_to_lidar, lidar_pos.T).T

    # Remove homogeneous coordinate
    camera_pos = camera_pos[:, :3] / camera_pos[:, 3:]

    # Project camera 3D points to 2D image plane
    pixel_pos = np.dot(
        camera_matrix, 
        np.dot(camera_to_lidar[:3,:3], 
               np.vstack((distance * np.cos(angle), 
                          -distance * np.sin(angle), 
                          np.zeros_like(distance), 
                          np.ones_like(distance)))))

    # Extract x and y coordinates from pixel_pos
    x, y = (pixel_pos[:-1, :]/pixel_pos[-1:, :]).T

    # Create a list of points to draw contours
    pts = np.array([(x[i], y[i]) for i in range(len(distance))], dtype=np.int32)

    # Draw contours on the frame
    cv2.drawContours(frame, [pts], 1, (0, 0, 255), 1)

    # Display the resulting frame
    cv2.imshow('frame', frame)

    # Exit the program on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the webcam and close all windows
cap.release()
cv2.destroyAllWindows()


# ############################
fx = float(1860.91182)
fy = float(1846.06954)
cx = float(393.70238)
cy = float(409.530228)

r00 = float(0.9971224)
r01 = float(-0.02865836)
r02 = float(-0.07018272)
r10 = float(0.01826659)
r11 = float(0.98934144)
r12 = float(-0.14446401)
r20 = float(0.07357478)
r21 = float(0.1427663)
r22 = float(0.987018)

t0 = float(-0.48266557)
t1 = float(3.51733443)
t2 = float(-0.48266557)

# ###########################
# fx = float(1860.91182)
# fy = float(1846.06954)
# cx = float(393.70238)
# cy = float(409.530228)

# r00 = float(0.99970798)
# r01 = float(-0.02403403)
# r02 = float(-0.0025132)
# r10 = float(0.02402181)
# r11 = float(0.99969998)
# r12 = float(-0.00478546)
# r20 = float(0.00262746)
# r21 = float(0.00472369)
# r22 = float(0.99998539)

# t0 = float(-4.86069745)
# t1 = float(-7.98533984)
# t2 = float(43.65714024)
