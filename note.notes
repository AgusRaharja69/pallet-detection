TASK THESIS:
1.  Method 1, Record data
2.  Method 2, Hitung angle camera dengan LiDAR, Record data
    ///////
    Say you are using RGB camera and have set it to 720p resolution. W = 1280, H = 720
    Assume the HFOV = 62 and VFOV=46 (Check values for your camera, assumed at random)
    Center of camera in image = (W/2,H/2) = (640,360)

    Horizontal Angle of say random pixel (x,y) = ((x - W/2)/(W/2))(HFOV/2)
    Vertical Angle of say random pixel (x,y) = ((y - H/2)/(H/2))(VFOV/2)

    For a random pixel say (320,180) it will be:
    H Angle = ((320 - 640)/640)(62/2) = - 15.5 degree
    H Angle = ((180 - 360)/360)(46/2) = - 11.5 degree

    You can get the euclidean angle by using simple (h-angle^2+v-angle^2)^0.5

    ///////
    (1280x1024)
    x,y=my_coordinates
    angle_per_pix=my_cam_angle/1280
    angle_vertical=(x-640)*angle_per_pix #-640 beacuse you want angle between middle of camera
    angle_horizontal=(x-512)*angle_per_pix
    ////////

3.  Method 3, Point cloud, setting posisi camera dengan point cloud LiDAR, Record Data
    ///////
    The overlap between a 2D lidar and an RGB image would be a line of pixels.

    If you have a feature detection in the RGB image that corresponds with that overlap, k
    then yes, its presumably possible to use the LIDAR information to fuse or 
    register the detection with the pointcloud or scan.

    if the goal is just camera calibration,
    there are usually ways that don't involve direct depth measurement
    (such as printing out a checkerboard)

Command training model :
py train.py --img 320 --batch 8 --epochs 50 --data data.yaml --device 0 --weights yolov5n.pt
py train.py --img 320 --batch 8 --epochs 10 --data data.yaml --device 0 --weights yolov5n.pt

Command detection:
py detectPallet.py --source 1 --device 0 --weights runs/train/exp21/weights/best.pt --weights-name yolov5n-100 --img 320
py yoloDetection.py --weights runs/train/exp16/weights/best.pt --weights-name yolov5s-100 --img 320

Weights name:
- yolov5m-10 : exp11
- yolov5m-25 : exp12
- yolov5m-50 : exp13
- yolov5m-75 : exp14
- yolov5m-100 : exp15
//
- yolov5s-100 : exp16
- yolov5s-75 : exp17
- yolov5s-50 : exp18
- yolov5s-25 : exp19
- yolov5s-10 : exp20
//
- yolov5n-100 : exp21
- yolov5n-75 : exp22
- yolov5n-50 : exp23
- yolov5n-25 : exp27
- yolov5n-10 : exp28

################## RUN DATA ##################
Focal length camera:
yolov5m [952.0,954.0,954.0,952.0,954.0,952.0,952.0,952.0,952.0,954.0,952.0,952.0,954.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0,954.0,952.0,952.0,954.0,954.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0,954.0,952.0,952.0,954.0,952.0,952.0,952.0,954.0,952.0,952.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0]
yolov5s [992.0,988.0,988.0,980.0,988.0,996.0,986.0,986.0,992.0,984.0,984.0,990.0,996.0,994.0,996.0,986.0,990.0,994.0,988.0,996.0,982.0,994.0,980.0,980.0,992.0,988.0,990.0,990.0,990.0,990.0,996.0,996.0,992.0,998.0,998.0,992.0,990.0,986.0,982.0,994.0,984.0,994.0,990.0,982.0,988.0,988.0,984.0,996.0,980.0,994.0,988.0,990.0,984.0,990.0,992.0,986.0,996.0,996.0,974.0,988.0,988.0,978.0,988.0,990.0,990.0,990.0,976.0,978.0,988.0,986.0,990.0,990.0,998.0,992.0,982.0,992.0,992.0,988.0,990.0,990.0,986.0,990.0,986.0,992.0,990.0,992.0,994.0,994.0,994.0,994.0,990.0,990.0,992.0,986.0,992.0,994.0,994.0,986.0,992.0,994.0,984.0,990.0,998.0,992.0,988.0,994.0,984.0,980.0,982.0,994.0,994.0,982.0,994.0,982.0,982.0,992.0,992.0,994.0,994.0,992.0,992.0,990.0,994.0,982.0,994.0,984.0,984.0,992.0,994.0,996.0,992.0,992.0,986.0,994.0,990.0,980.0,988.0,988.0,970.0,988.0,988.0,982.0,982.0,990.0,990.0,986.0,990.0,990.0,988.0,992.0,994.0,980.0,994.0,988.0,990.0,986.0,982.0]
yolov5n [980.0,982.0,970.0,982.0,966.0,966.0,976.0,980.0,986.0,982.0,962.0,980.0,968.0,976.0,962.0,968.0,968.0,984.0,980.0,984.0,982.0,976.0,978.0,972.0,974.0,984.0,988.0,976.0,954.0,974.0,974.0,976.0,976.0,974.0,974.0,980.0,974.0,968.0,968.0,982.0,972.0,978.0,978.0,976.0,980.0,956.0,972.0,980.0,954.0,976.0,980.0,978.0,988.0,980.0,978.0,978.0,978.0,976.0,976.0,984.0,964.0,964.0,982.0,978.0,984.0,964.0,988.0,988.0,980.0,992.0]

Distance using method 1:
[1] 100
m1 (99.797) = [99.655,99.864,99.864,99.864,99.655,99.865,99.655,99.864,99.655,99.655,99.865,99.655,99.655,100.074,99.864,100.074,99.865,99.655,99.655,99.864,99.655,99.864,99.864,99.864,99.864,99.655,99.655,99.655,99.864,99.864,100.074]
s1 (101.208) = [101.34,101.34,101.132,101.132,100.927,101.132,100.721,101.133,103.039,101.132,101.34,101.133,101.133,101.133,100.927,101.134,101.34,101.133,101.34,101.133,101.133,101.133,101.34,101.133,100.927,100.927,101.132,100.927,101.133,101.34,101.548]
n1 (102.874) = [103.387,103.169,105.863,102.515,102.515,103.609,102.517,102.302,101.661,102.302,102.302,104.051,102.517,102.517,102.517,100.818,102.302,102.951,102.951,103.609,102.517,102.517,102.517,101.875,102.951,103.829,103.829,102.951,102.086,104.053,103.609]
[2] 150
[3] 200
[4] 250
[5] 300
[6] 350

LiDAR real world potition:
h_LiDAR = 10.5 cm
h_camera = 14.5 cm
